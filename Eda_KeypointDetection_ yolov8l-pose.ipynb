{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8419315,"sourceType":"datasetVersion","datasetId":5012052}],"dockerImageVersionId":30839,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport json\nimport os\n\nfrom PIL import Image\nimport io\nimport base64\nimport math\n\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom shapely.geometry import Polygon","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:25:14.099003Z","iopub.execute_input":"2025-01-29T20:25:14.099218Z","iopub.status.idle":"2025-01-29T20:25:16.798912Z","shell.execute_reply.started":"2025-01-29T20:25:14.099197Z","shell.execute_reply":"2025-01-29T20:25:16.797939Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def order_points_convex(points):\n    \"\"\"\n    Orders the points to form a convex quadrilateral (rectangle).\n    \"\"\"\n    if len(points) != 4:\n        return points  # Only works for quadrilaterals\n    \n    # Calculate the centroid of the points\n    centroid_x = sum(p[0] for p in points) / 4\n    centroid_y = sum(p[1] for p in points) / 4\n    \n    # Sort points by angle relative to the centroid\n    def angle_from_centroid(point):\n        return math.atan2(point[1] - centroid_y, point[0] - centroid_x)\n    \n    sorted_points = sorted(points, key=angle_from_centroid)\n    return sorted_points\n    \ndef filter_images_with_4_plus_keypoints(directory):\n    \"\"\"\n    Filters images that have polygons with more than 4 keypoints.\n    Returns a list of file paths for such images.\n    \"\"\"\n    json_files = [f for f in os.listdir(directory) if f.endswith(\".json\")]\n    filtered_files = []\n\n    for filename in json_files:\n        json_path = os.path.join(directory, filename)\n        with open(json_path, 'r') as f:\n            keypoints = json.load(f)\n        \n        if \"shapes\" not in keypoints:\n            continue\n        \n        for shape in keypoints[\"shapes\"]:\n            if len(shape[\"points\"]) > 4:\n                filtered_files.append(json_path)\n                break  # Stop checking other shapes in the same file\n    \n    return filtered_files\n    \ndef is_convex(points):\n    \"\"\"\n    Checks if the given points form a convex polygon.\n    \"\"\"\n    if len(points) < 3:\n        return False  # A polygon must have at least 3 points\n    \n    polygon = Polygon(points)\n    return polygon.is_valid and polygon.convex_hull.equals(polygon)\n    \ndef ensure_rectangle_shape(points):\n    \"\"\"\n    Ensures the points form a rectangle-shaped polygon.\n    \"\"\"\n    if len(points) != 4:\n        return points  # Only works for quadrilaterals\n    \n    # Order the points to form a convex quadrilateral\n    ordered_points = order_points_convex(points)\n    \n    # Check if the ordered points form a convex polygon\n    if is_convex(ordered_points):\n        return ordered_points\n    else:\n        # If not convex, adjust the points slightly\n        adjusted_points = [(x + 0.01 * i, y + 0.01 * i) for i, (x, y) in enumerate(ordered_points)]\n        return adjusted_points\n\n\ndef find_closest_points(points):\n    min_distance = float('inf')\n    closest_pair = None\n    \n    for i in range(len(points)):\n        for j in range(i + 1, len(points)):\n            x1, y1 = points[i]\n            x2, y2 = points[j]\n            distance = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n            if distance < min_distance:\n                min_distance = distance\n                closest_pair = (i, j)\n    \n    return closest_pair\n    \ndef replace_closest_points(points):\n    if len(points) > 4:\n        # Find the two closest points\n        i, j = find_closest_points(points)\n        # Calculate the midpoint of the two closest points\n        midpoint = (\n            (points[i][0] + points[j][0]) / 2,\n            (points[i][1] + points[j][1]) / 2\n        )\n        # Replace the two closest points with the midpoint\n        new_points = [point for idx, point in enumerate(points) if idx not in (i, j)]\n        new_points.append(midpoint)\n        return new_points\n    return points\ndef reorder_points(points):\n    \"\"\"\n    Reorders the points to ensure:\n    - x1: top-left\n    - x2: top-right\n    - x3: bottom-right\n    - x4: bottom-left\n    \"\"\"\n    if len(points) != 4:\n        return points  # Only works for quadrilaterals\n    \n    # Sort points by y-coordinate (top to bottom)\n    sorted_by_y = sorted(points, key=lambda p: p[1])\n    \n    # Separate top and bottom points\n    top_points = sorted_by_y[:2]  # Top two points (smallest y)\n    bottom_points = sorted_by_y[2:]  # Bottom two points (largest y)\n    \n    # Sort top points by x-coordinate (left to right)\n    top_points_sorted = sorted(top_points, key=lambda p: p[0])\n    x1 = top_points_sorted[0]  # Top-left\n    x2 = top_points_sorted[1]  # Top-right\n    \n    # Sort bottom points by x-coordinate (left to right)\n    bottom_points_sorted = sorted(bottom_points, key=lambda p: p[0])\n    x4 = bottom_points_sorted[0]  # Bottom-left\n    x3 = bottom_points_sorted[1]  # Bottom-right\n    \n    # Return reordered points\n    return [x1, x2, x3, x4]\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T18:34:17.172869Z","iopub.execute_input":"2025-01-28T18:34:17.173153Z","iopub.status.idle":"2025-01-28T18:34:17.183931Z","shell.execute_reply.started":"2025-01-28T18:34:17.173134Z","shell.execute_reply":"2025-01-28T18:34:17.183059Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_data = []\nlabel_dir = '/kaggle/input/surround-view-mmu-parking-slots-dataset/main_data/labels'\nlabel_files = os.listdir('/kaggle/input/surround-view-mmu-parking-slots-dataset/main_data/labels')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:25:19.769571Z","iopub.execute_input":"2025-01-29T20:25:19.769926Z","iopub.status.idle":"2025-01-29T20:25:20.212966Z","shell.execute_reply.started":"2025-01-29T20:25:19.769894Z","shell.execute_reply":"2025-01-29T20:25:20.212201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for file_name in label_files:\n    if file_name.endswith('.json'):\n        with open(os.path.join(label_dir, file_name), 'r') as f:\n            label_data.append(json.load(f))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:25:20.213974Z","iopub.execute_input":"2025-01-29T20:25:20.214207Z","iopub.status.idle":"2025-01-29T20:27:15.254828Z","shell.execute_reply.started":"2025-01-29T20:25:20.214186Z","shell.execute_reply":"2025-01-29T20:27:15.254105Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rows = []\nfor labels in label_data:\n    for shape in labels['shapes']:\n        true_flags = [key for key, value in labels['flags'].items() if value]\n        if len(true_flags) > 1:\n            print(\"more than one\")\n        for flag in true_flags:\n            row= ({\n                'flag': flag, \n                'imagePath': labels['imagePath'],\n                'imageHeight': labels['imageHeight'],\n                'imageWidth': labels['imageWidth'],\n                'label': shape['label'],\n            })\n            points = shape[\"points\"]\n            if len(points) > 4:\n                continue\n\n            for i, (x, y) in enumerate(points):\n                row[f'x{i+1}'] = x\n                row[f'y{i+1}'] = y\n            rows.append(row)\n\ndata = pd.DataFrame(rows)\ndata.dropna()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:27:15.256111Z","iopub.execute_input":"2025-01-29T20:27:15.256377Z","iopub.status.idle":"2025-01-29T20:27:15.448404Z","shell.execute_reply.started":"2025-01-29T20:27:15.256349Z","shell.execute_reply":"2025-01-29T20:27:15.447256Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_map = {\"occupied\": 0, \"vacant\": 1, \"unavailable\": 2}\nreverse = {0: \"occupied\", 1: \"vacant\", 2: \"unavailable\"}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:27:52.737919Z","iopub.execute_input":"2025-01-29T20:27:52.738267Z","iopub.status.idle":"2025-01-29T20:27:52.7424Z","shell.execute_reply.started":"2025-01-29T20:27:52.738241Z","shell.execute_reply":"2025-01-29T20:27:52.741267Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.fillna(0, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:27:52.983273Z","iopub.execute_input":"2025-01-29T20:27:52.983588Z","iopub.status.idle":"2025-01-29T20:27:52.996412Z","shell.execute_reply.started":"2025-01-29T20:27:52.983563Z","shell.execute_reply":"2025-01-29T20:27:52.995625Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data, val_data = train_test_split(data, test_size=0.2, random_state=28)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:27:53.295973Z","iopub.execute_input":"2025-01-29T20:27:53.296386Z","iopub.status.idle":"2025-01-29T20:27:53.307542Z","shell.execute_reply.started":"2025-01-29T20:27:53.296349Z","shell.execute_reply":"2025-01-29T20:27:53.306699Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:27:54.476289Z","iopub.execute_input":"2025-01-29T20:27:54.476586Z","iopub.status.idle":"2025-01-29T20:27:54.501047Z","shell.execute_reply.started":"2025-01-29T20:27:54.476559Z","shell.execute_reply":"2025-01-29T20:27:54.500125Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create directories for train and val\nos.makedirs(\"dataset/train/labels\", exist_ok=True)\nos.makedirs(\"dataset/val/labels\", exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:27:58.847261Z","iopub.execute_input":"2025-01-29T20:27:58.847599Z","iopub.status.idle":"2025-01-29T20:27:58.852423Z","shell.execute_reply.started":"2025-01-29T20:27:58.847568Z","shell.execute_reply":"2025-01-29T20:27:58.851446Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Number of unique groups\nnum_groups = len(train_data.groupby('imagePath'))\nprint(\"Number of unique groups:\", num_groups)\n\n# Find the longest group\ngroup_sizes = train_data.groupby('imagePath').size()\nlongest_group = group_sizes.idxmax()  # Group with the maximum size\nlongest_group_size = group_sizes.max()  # Size of the longest group\n\nprint(f\"Longest group: {longest_group} with {longest_group_size} entries\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:27:59.343708Z","iopub.execute_input":"2025-01-29T20:27:59.344084Z","iopub.status.idle":"2025-01-29T20:27:59.42819Z","shell.execute_reply.started":"2025-01-29T20:27:59.344057Z","shell.execute_reply":"2025-01-29T20:27:59.427391Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_yolo_format(data, output_dir):\n    i = 0\n    for image_path, group in data.groupby('imagePath'):\n        # Construct the file name for the annotation file\n        label_path = os.path.join(output_dir, image_path.replace(\".jpg\", \".txt\"))\n        with open(label_path, 'w+') as f:\n            for _, row in group.iterrows():\n                # Image dimensions\n                img_width = row[\"imageWidth\"]\n                img_height = row[\"imageHeight\"]\n        \n                # Normalize coordinates\n                x1 = max(min(row[\"x1\"] / img_width, 1), 0)\n                y1 = max(min(row[\"y1\"] / img_height, 1), 0)\n                x2 = max(min(row[\"x2\"] / img_width, 1), 0)\n                y2 = max(min(row[\"y2\"] / img_height, 1), 0)\n                x3 = max(min(row[\"x3\"] / img_width, 1), 0)\n                y3 = max(min(row[\"y3\"] / img_height, 1), 0)\n                x4 = max(min(row[\"x4\"] / img_width, 1), 0)\n                y4 = max(min(row[\"y4\"] / img_height, 1), 0)\n        \n                # Calculate bounding box\n                x_center = (x1 + x2 + x3 + x4) / 4\n                y_center = (y1 + y2 + y3 + y4) / 4\n                width = max(x1, x2, x3, x4) - min(x1, x2, x3, x4)\n                height = max(y1, y2, y3, y4) - min(y1, y2, y3, y4)\n        \n                # Get class ID\n                class_id = label_map[row[\"label\"]]\n        \n                # YOLO format\n                yolo_row = [\n                    class_id, x_center, y_center, width, height,\n                    x1, y1, 2, x2, y2, 2, x3, y3, 2, x4, y4, 2\n                ]\n\n                norm = [\n                     x_center, y_center, width, height,\n                    x1, y1,  x2, y2, x3, y3, x4, y4\n                ]\n                \n                # Applying checks to see if data is good to go\n                if x1 < 0 or y1 < 0 or x2 < 0 or y2 < 0:\n                    print(f\"Invalid bounding box in {image_path}\")\n                    continue\n                \n                if width < 0 or height < 0:\n                    print(f\"Negative dimensions detected in {image_path}\")\n                    continue\n                \n                if any(map(lambda c: c != c or c == float('inf') or c == float('-inf') or (0 > c or c > 1), norm)):  # Check NaN or inf\n                    print(f\"Invalid coordinates detected in {image_path}: {norm}\")\n                    print(row['x4'] , img_height)\n                    print(x1,x2,x3,x4,y1,y2,y3,y4)\n                    continue\n                    \n                if not (0 <= x_center <= 1 and 0 <= y_center <= 1):\n                    print(f\"Center out of bounds in {image_path}: x_center={x_center}, y_center={y_center}\")\n                    continue\n                    \n                if width <= 0 or height <= 0:\n                    print(f\"Invalid bounding box dimensions in {image_path}: width={width}, height={height}\")\n                    continue\n            \n                yolo_data = \" \".join(map(str, yolo_row))\n                f.write(yolo_data+'\\n')\n                f.flush()\n    return yolo_data, row.imagePath","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:28:03.462429Z","iopub.execute_input":"2025-01-29T20:28:03.462759Z","iopub.status.idle":"2025-01-29T20:28:03.473301Z","shell.execute_reply.started":"2025-01-29T20:28:03.46273Z","shell.execute_reply":"2025-01-29T20:28:03.472523Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def show_example_from_file(filename):\n    with open(filename, 'r') as f:\n        keypoints = json.load(f)\n    detections = keypoints[\"shapes\"]\n    image = Image.open(filename.replace(\"json\", \"jpg\").replace(\"labels\", \"images\"))\n    \n    fig, ax = plt.subplots(figsize=(10, 8))\n    \n    ax.imshow(image)\n    for points in detections:\n        x_coords, y_coords = zip(*points[\"points\"])\n        ax.plot(x_coords + (x_coords[0],), y_coords + (y_coords[0],), marker='o', linestyle='-', label=points[\"label\"])\n        ax.fill(x_coords, y_coords, alpha=0.3)  # Optional: fill the polygon\n        centroid_x = sum(x_coords) / len(x_coords)\n        centroid_y = sum(y_coords) / len(y_coords)\n        ax.text(centroid_x, centroid_y, points[\"label\"], fontsize=12, color='white', ha='center', va='center')\n        ax.legend()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:28:05.570272Z","iopub.execute_input":"2025-01-29T20:28:05.570573Z","iopub.status.idle":"2025-01-29T20:28:05.576382Z","shell.execute_reply.started":"2025-01-29T20:28:05.570548Z","shell.execute_reply":"2025-01-29T20:28:05.575525Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TEST_FILE = \"/kaggle/input/surround-view-mmu-parking-slots-dataset/main_data/labels/0926_2284.json\"\nshow_example_from_file(TEST_FILE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:28:07.585021Z","iopub.execute_input":"2025-01-29T20:28:07.585347Z","iopub.status.idle":"2025-01-29T20:28:08.225961Z","shell.execute_reply.started":"2025-01-29T20:28:07.585321Z","shell.execute_reply":"2025-01-29T20:28:08.225114Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Process and save train and validation data\nex_ann_train, ex_image_train = save_yolo_format(train_data, \"dataset/train/labels\")\nex_ann_val, ex_image_val= save_yolo_format(val_data, \"dataset/val/labels\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:28:10.439892Z","iopub.execute_input":"2025-01-29T20:28:10.440182Z","iopub.status.idle":"2025-01-29T20:28:14.972285Z","shell.execute_reply.started":"2025-01-29T20:28:10.44016Z","shell.execute_reply":"2025-01-29T20:28:14.971486Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ex_ann_train, ex_image_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:28:14.97368Z","iopub.execute_input":"2025-01-29T20:28:14.974051Z","iopub.status.idle":"2025-01-29T20:28:14.978924Z","shell.execute_reply.started":"2025-01-29T20:28:14.974013Z","shell.execute_reply":"2025-01-29T20:28:14.978202Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:31:10.647254Z","iopub.execute_input":"2025-01-29T20:31:10.647533Z","iopub.status.idle":"2025-01-29T20:31:10.665341Z","shell.execute_reply.started":"2025-01-29T20:31:10.6475Z","shell.execute_reply":"2025-01-29T20:31:10.664231Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:31:10.666345Z","iopub.execute_input":"2025-01-29T20:31:10.666589Z","iopub.status.idle":"2025-01-29T20:31:15.628338Z","shell.execute_reply.started":"2025-01-29T20:31:10.666568Z","shell.execute_reply":"2025-01-29T20:31:15.627351Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save images to respective directories (assuming they're all in one directory)\nos.makedirs(\"dataset/train/images\", exist_ok=True)\nos.makedirs(\"dataset/val/images\", exist_ok=True)\ntrain_images = train_data.groupby('imagePath')\nval_images = val_data.groupby('imagePath')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:31:46.87203Z","iopub.execute_input":"2025-01-29T20:31:46.872403Z","iopub.status.idle":"2025-01-29T20:31:46.884503Z","shell.execute_reply.started":"2025-01-29T20:31:46.872374Z","shell.execute_reply":"2025-01-29T20:31:46.883618Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for image in train_images.groups.keys():\n    os.system(f\"cp {os.path.join('/kaggle/input/surround-view-mmu-parking-slots-dataset/main_data/images', image)} dataset/train/images/\")  # Copy images to train folder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:28:23.164711Z","iopub.execute_input":"2025-01-29T20:28:23.165052Z","iopub.status.idle":"2025-01-29T20:30:42.922757Z","shell.execute_reply.started":"2025-01-29T20:28:23.165027Z","shell.execute_reply":"2025-01-29T20:30:42.921638Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Train Images Successfully Pasted\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:30:42.924058Z","iopub.execute_input":"2025-01-29T20:30:42.924387Z","iopub.status.idle":"2025-01-29T20:30:42.929303Z","shell.execute_reply.started":"2025-01-29T20:30:42.924355Z","shell.execute_reply":"2025-01-29T20:30:42.928349Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for image in val_images.groups.keys():\n    os.system(f\"cp {os.path.join('/kaggle/input/surround-view-mmu-parking-slots-dataset/main_data/images', image)} dataset/val/images/\")  # Copy images to train folder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:30:42.93099Z","iopub.execute_input":"2025-01-29T20:30:42.931234Z","iopub.status.idle":"2025-01-29T20:31:10.621198Z","shell.execute_reply.started":"2025-01-29T20:30:42.931212Z","shell.execute_reply":"2025-01-29T20:31:10.620403Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Validation Images Successfully Pasted\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:31:10.622563Z","iopub.execute_input":"2025-01-29T20:31:10.622846Z","iopub.status.idle":"2025-01-29T20:31:10.62718Z","shell.execute_reply.started":"2025-01-29T20:31:10.622813Z","shell.execute_reply":"2025-01-29T20:31:10.626476Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport random\n\n# Define dataset paths\ntrain_images_path = \"/kaggle/working/dataset/train/images\"\ntrain_labels_path = \"/kaggle/working/dataset/train/labels\"\nval_images_path = \"/kaggle/working/dataset/val/images\"\nval_labels_path = \"/kaggle/working/dataset/val/labels\"\n\n# Function to display random file and corresponding label\ndef get_random_file_and_label(images_path, labels_path):\n    random_image_file = random.choice(os.listdir(images_path))\n    image_file_path = os.path.join(images_path, random_image_file)\n    label_file_path = os.path.join(labels_path, random_image_file.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\"))\n\n    with open(label_file_path, 'r') as label_file:\n        label_content = label_file.read()\n\n    return os.path.join(images_path, random_image_file), label_content\n\n\ndef draw_bbox_multiple(images_annotations):\n    \"\"\"\n    Draws bounding boxes and vertices on multiple images and displays them in subplots.\n    :param images_annotations: List of tuples [(image_path, annotation), ...].\n    \"\"\"\n    num_images = len(images_annotations)\n    cols = 3  # Define the number of columns for subplots\n    rows = (num_images + cols - 1) // cols  # Calculate the number of rows\n\n    fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n    axes = axes.flatten() if num_images > 1 else [axes]\n\n    for idx, (image_path, annotation) in enumerate(images_annotations):\n        if not os.path.exists(image_path):\n            print(f\"Image not found: {image_path}\")\n            axes[idx].axis('off')\n            continue\n\n        img = cv2.imread(image_path)\n        h, w = img.shape[:2]\n\n        data = list(map(float, annotation.split()))\n        class_id = int(data[0])\n        x_center, y_center, bbox_width, bbox_height = data[1:5]\n        coords = [\n            (data[i] * (w if i % 2 == 0 else h), data[i + 1] * (h if i % 2 == 0 else w), int(data[i + 2]))\n            for i in range(5, 15, 3)\n        ]\n\n        # Filter visible points\n        visible_points = [(int(x), int(y)) for x, y, visible in coords if visible == 2]\n\n        # Draw polygon and visible points\n        if len(visible_points) >= 3:\n            cv2.polylines(img, [np.array(visible_points, dtype=np.int32)], isClosed=True, color=(0, 255, 0), thickness=2)\n        for x, y in visible_points:\n            cv2.circle(img, (x, y), radius=5, color=(0, 255, 0), thickness=-1)\n\n        # Plot the image\n        axes[idx].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n        axes[idx].set_title(f\"Class ID: {reverse[class_id]}, Image: {image_path.split('/')[-1]}\")\n        axes[idx].axis('off')\n\n    # Hide any unused subplot axes\n    for idx in range(num_images, len(axes)):\n        axes[idx].axis('off')\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:31:10.628061Z","iopub.execute_input":"2025-01-29T20:31:10.628282Z","iopub.status.idle":"2025-01-29T20:31:10.646321Z","shell.execute_reply.started":"2025-01-29T20:31:10.628262Z","shell.execute_reply":"2025-01-29T20:31:10.645205Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"draw_bbox_multiple([get_random_file_and_label(train_images_path, train_labels_path) for i in range(15)])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T08:25:46.642079Z","iopub.execute_input":"2025-01-23T08:25:46.642424Z","iopub.status.idle":"2025-01-23T08:25:46.656204Z","shell.execute_reply.started":"2025-01-23T08:25:46.642398Z","shell.execute_reply":"2025-01-23T08:25:46.655081Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install ultralytics --upgrade -q\n\nimport ultralytics\nultralytics.checks()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:31:50.715243Z","iopub.execute_input":"2025-01-29T20:31:50.715554Z","iopub.status.idle":"2025-01-29T20:32:01.009397Z","shell.execute_reply.started":"2025-01-29T20:31:50.715529Z","shell.execute_reply":"2025-01-29T20:32:01.008285Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import yaml\n\n# Define the data structure\ndata = {\n    \"kpt_shape\": [4, 3],      # list of integers\n    \"flip_idx\": [1, 0, 3, 2], # list of integers\n    \"names\": {0: \"occupied\", 1: 'vacant', 2: 'unavailable'},\n    \"nc\": 3,\n    \"train\": \"/kaggle/working/dataset/train/images\",  # train images (relative to 'path')\n    \"val\": \"/kaggle/working/dataset/val/images\",      # val images (relative to 'path')\n}\n\n# Write to a YAML file\nwith open(\"dataset/data.yaml\", \"w\") as file:\n    yaml.dump(data, file, default_flow_style=False, sort_keys=False)\n\nprint(\"YAML file 'config.yaml' created successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:32:01.010849Z","iopub.execute_input":"2025-01-29T20:32:01.011282Z","iopub.status.idle":"2025-01-29T20:32:01.01993Z","shell.execute_reply.started":"2025-01-29T20:32:01.011259Z","shell.execute_reply":"2025-01-29T20:32:01.019053Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\n\nmodel = YOLO('yolov8l-pose.pt')\n\nresults = model.train(data=f\"/kaggle/working/dataset/data.yaml\", epochs=50, imgsz=640)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:32:01.021353Z","iopub.execute_input":"2025-01-29T20:32:01.021621Z","iopub.status.idle":"2025-01-29T22:35:52.693355Z","shell.execute_reply.started":"2025-01-29T20:32:01.021599Z","shell.execute_reply":"2025-01-29T22:35:52.692214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:05:05.897177Z","iopub.execute_input":"2025-01-23T06:05:05.897389Z","iopub.status.idle":"2025-01-23T06:05:05.91394Z","shell.execute_reply.started":"2025-01-23T06:05:05.897371Z","shell.execute_reply":"2025-01-23T06:05:05.913345Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:05:05.914606Z","iopub.execute_input":"2025-01-23T06:05:05.914824Z","iopub.status.idle":"2025-01-23T06:05:05.932654Z","shell.execute_reply.started":"2025-01-23T06:05:05.914807Z","shell.execute_reply":"2025-01-23T06:05:05.931894Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat /usr/local/lib/python3.10/dist-packages/ultralytics/utils/callbacks/raytune.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:05:05.933443Z","iopub.execute_input":"2025-01-23T06:05:05.933698Z","iopub.status.idle":"2025-01-23T06:05:06.116754Z","shell.execute_reply.started":"2025-01-23T06:05:05.933673Z","shell.execute_reply":"2025-01-23T06:05:06.116004Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import ray\nfrom ray import tune\nfrom ray.air import session\n\nif ray.train._internal.session._get_session() is not None:\n    metrics = trainer.metrics\n    metrics['epoch'] = trainer.epoch\n    session.report(metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T05:55:21.237335Z","iopub.execute_input":"2025-01-23T05:55:21.237692Z","iopub.status.idle":"2025-01-23T05:55:21.242274Z","shell.execute_reply.started":"2025-01-23T05:55:21.23766Z","shell.execute_reply":"2025-01-23T05:55:21.241514Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}